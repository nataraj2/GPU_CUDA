{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXsGtOvpBlyX",
        "outputId": "97201c76-e878-4602-c982-84655813472b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-tu97qdwn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-tu97qdwn\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=f0d94ec5301615cc9093c96994c16161291ded574188869ea86366aa14e85393\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1ypfec78/wheels/db/c1/1f/a2bb07bbb4a1ce3c43921252aeafaa6205f08637e292496f04\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name my_curand.cu \n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <vector>\n",
        "\n",
        "#include </content/src/ParallelForCPU.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "HOST DEVICE\n",
        "inline void test_function(int i, int j, int k, \n",
        "                          Array4<double> const &vel,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tArray4<double> const &pressure) {\n",
        "\tvel(i, j, k) = i+j+k;\n",
        "\tpressure(i,j,k) = 2*i*j;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\t\n",
        "\tint nx = 5, ny = 4, nz = 3;\n",
        "    \n",
        "\n",
        "\n",
        "\tMultiFab velfab(nx, ny, nz);\n",
        "\tMultiFab pressurefab(nx, ny, nz);\n",
        "\n",
        "\tauto vel = velfab.array();\n",
        "\tauto pressure = pressurefab.array();\n",
        "  \n",
        "\tParallelFor(nx, ny, nz,\n",
        "\t[=] DEVICE (int i, int j, int k)noexcept\n",
        "\t{\n",
        "\t\ttest_function(i, j, k, vel, pressure);\n",
        "\t});\n",
        "\n",
        "\tcudaDeviceSynchronize();\n",
        "\n",
        "\tfor(int i=0;i<nx;i++){\n",
        "\t\tfor(int j=0;j<ny;j++){\n",
        "\t\t\tfor(int k=0;k<nz;k++){\n",
        "\t\t\t\tcout << \"Vel at \" << i << \",\" << j << \",\" << k << \" is \" << vel(i,j,k) << \" \" << pressure(i,j,k) << \"\\n\";\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zi1hPjyNKyGr",
        "outputId": "f143659c-dbae-4f8b-b32d-3d17c8b40e3a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/my_curand.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name ParallelForGPU.h\n",
        "\n",
        "#define HOST __host__\n",
        "#define DEVICE __device__\n",
        "\n",
        "#define LAUNCH_KERNEL(MT, blocks, threads, sharedMem, ... ) \\\n",
        "        launch_global<MT><<<blocks, threads, sharedMem>>>(__VA_ARGS__)\n",
        "\n",
        "template<typename T>\n",
        "struct Array4{\n",
        "\tT* data;\n",
        "\tint jstride;\n",
        "\tint kstride;\n",
        "\n",
        "  constexpr Array4(T* a_p): data(a_p){};\n",
        "\n",
        "\tpublic:\n",
        "    \t__host__ __device__\n",
        "\t\tT& operator()(int i, int j, int k)const noexcept{\n",
        "\t\t\t\t\t\treturn data[i + j*jstride + k*kstride];\n",
        "\t\t}\n",
        "};\n",
        "\n",
        "template<int launch_bounds_max_threads, class L>\n",
        "__launch_bounds__(launch_bounds_max_threads)\n",
        "__global__ void launch_global (L f0) { f0(); }\n",
        "\n",
        "template <typename F>\n",
        "DEVICE\n",
        "auto call_f(F const &f, int i, int j, int k){\n",
        "\tf(i, j, k);\n",
        "}\n",
        "\n",
        "template<class L>\n",
        "void ParallelFor(int nx, int ny, int nz, L &&f){\n",
        "\t\tint len_xy = nx*ny;\n",
        "\t\tint len_x = nx;\n",
        "\t\tLAUNCH_KERNEL(512, 2, 10, 0,\n",
        "    \t\t[=] DEVICE () noexcept{\t\n",
        "\t\t\tfor(int icell = blockDim.x*blockIdx.x+threadIdx.x, stride = blockDim.x*gridDim.x;\n",
        "        \ticell < nx*ny*nz; icell += stride){\n",
        "\t\t\t\tint k = icell/len_xy;\n",
        "\t\t\t\tint j = (icell - k*len_xy)/len_x;\n",
        "\t\t\t\tint i = (icell - k*len_xy - j*len_x); \n",
        "\t\t\t\tcall_f(f, i, j, k);\t\n",
        "\t\t\t}\n",
        "\t\t});\n",
        "}\n",
        "\n",
        "template <typename T>\n",
        "HOST DEVICE inline\n",
        "Array4<T>\n",
        "makeArray4 (T* p) noexcept\n",
        "{ \n",
        "    return Array4<T>{p};\n",
        "}\n",
        "\n",
        "class MultiFab{\n",
        "\t\t\n",
        "\t\tint nx, ny, nz;\n",
        "\n",
        "\t\tpublic:\n",
        "\t\t\n",
        "\t\tMultiFab(int a_nx, int a_ny, int a_nz): nx(a_nx), ny(a_ny), nz(a_nz){};\n",
        "\n",
        "\t\tArray4<double> array()\n",
        "\t\t{\n",
        "\t\t\t\tArray4<double> *vec;\n",
        "  \t\t\tcudaMallocManaged((void**)&vec, sizeof(Array4<double>));\n",
        "  \t\t\tcudaMallocManaged((void**)&(vec[0].data), nx*ny*nz*sizeof(double));\n",
        "\t\t\t\tvec[0].jstride = nx;\n",
        "\t\t\t\tvec[0].kstride = nx*ny;\n",
        "\t\t\t\treturn vec[0];\n",
        "\t\t}\t\t\n",
        "};"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vsf5hDw3EHTD",
        "outputId": "d26d7708-750c-4320-ae3b-3f42ab5f94a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/ParallelForGPU.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name ParallelForCPU.h\n",
        "\n",
        "#define HOST \n",
        "#define DEVICE \n",
        "\n",
        "template<typename T>\n",
        "struct Array4{\n",
        "\tT* data;\n",
        "\tint jstride;\n",
        "\tint kstride;\n",
        "\n",
        "  constexpr Array4(T* a_p): data(a_p){};\n",
        "\n",
        "\tpublic:\n",
        "    \t__host__ __device__\n",
        "\t\tT& operator()(int i, int j, int k)const noexcept{\n",
        "\t\t\t\t\t\treturn data[i + j*jstride + k*kstride];\n",
        "\t\t}\n",
        "};\n",
        "\n",
        "template <typename F>\n",
        "auto call_f(F const &f, int i, int j, int k){\n",
        "\tf(i, j, k);\n",
        "}\n",
        "\n",
        "template<class L>\n",
        "void ParallelFor(int nx, int ny, int nz, L &&f){\n",
        "\tfor(int i=0;i<nx;i++){\n",
        "\t  for(int j=0;j<ny;j++){\n",
        "\t\t\t\tfor(int k=0;k<nz;k++){\n",
        "\t\t\t\tcall_f(f, i, j, k);\t\n",
        "\t\t\t}\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "class MultiFab{\n",
        "\t\t\n",
        "\t\tint nx, ny, nz;\n",
        "\n",
        "\t\tpublic:\n",
        "\t\t\n",
        "\t\tMultiFab(int a_nx, int a_ny, int a_nz): nx(a_nx), ny(a_ny), nz(a_nz){};\n",
        "\n",
        "\t\tArray4<double> array()\n",
        "\t\t{\n",
        "\t\t\t\tArray4<double> *vec;\n",
        "        vec = (Array4<double>*)malloc(sizeof(Array4<double>));\n",
        "        vec[0].data = (double*)malloc(nx*ny*nz*sizeof(double));\n",
        "\t\t\t\tvec[0].jstride = nx;\n",
        "\t\t\t\tvec[0].kstride = nx*ny;\n",
        "\t\t\t\treturn vec[0];\n",
        "\t\t}\t\t\n",
        "};"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rtLOSJLmJPxG",
        "outputId": "fa514ce1-3b2f-44c3-b188-72ac44b9c09d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/ParallelForCPU.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -expt-extended-lambda --expt-relaxed-constexpr --forward-unknown-to-host-compiler --Werror ext-lambda-captures-this -Xcudafe --diag_suppress=esa_on_defaulted_function_ignored -o /content/src/my_curand /content/src/my_curand.cu -lcurand\n"
      ],
      "metadata": {
        "id": "0VMQbIGlLCps"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!compute-sanitizer /content/src/my_curand\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiCSoucHLFoz",
        "outputId": "6c747752-26a5-48ca-a571-6936da3784f1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= COMPUTE-SANITIZER\n",
            "Vel at 0,0,0 is 0 0\n",
            "Vel at 0,0,1 is 1 0\n",
            "Vel at 0,0,2 is 2 0\n",
            "Vel at 0,1,0 is 1 0\n",
            "Vel at 0,1,1 is 2 0\n",
            "Vel at 0,1,2 is 3 0\n",
            "Vel at 0,2,0 is 2 0\n",
            "Vel at 0,2,1 is 3 0\n",
            "Vel at 0,2,2 is 4 0\n",
            "Vel at 0,3,0 is 3 0\n",
            "Vel at 0,3,1 is 4 0\n",
            "Vel at 0,3,2 is 5 0\n",
            "Vel at 1,0,0 is 1 0\n",
            "Vel at 1,0,1 is 2 0\n",
            "Vel at 1,0,2 is 3 0\n",
            "Vel at 1,1,0 is 2 2\n",
            "Vel at 1,1,1 is 3 2\n",
            "Vel at 1,1,2 is 4 2\n",
            "Vel at 1,2,0 is 3 4\n",
            "Vel at 1,2,1 is 4 4\n",
            "Vel at 1,2,2 is 5 4\n",
            "Vel at 1,3,0 is 4 6\n",
            "Vel at 1,3,1 is 5 6\n",
            "Vel at 1,3,2 is 6 6\n",
            "Vel at 2,0,0 is 2 0\n",
            "Vel at 2,0,1 is 3 0\n",
            "Vel at 2,0,2 is 4 0\n",
            "Vel at 2,1,0 is 3 4\n",
            "Vel at 2,1,1 is 4 4\n",
            "Vel at 2,1,2 is 5 4\n",
            "Vel at 2,2,0 is 4 8\n",
            "Vel at 2,2,1 is 5 8\n",
            "Vel at 2,2,2 is 6 8\n",
            "Vel at 2,3,0 is 5 12\n",
            "Vel at 2,3,1 is 6 12\n",
            "Vel at 2,3,2 is 7 12\n",
            "Vel at 3,0,0 is 3 0\n",
            "Vel at 3,0,1 is 4 0\n",
            "Vel at 3,0,2 is 5 0\n",
            "Vel at 3,1,0 is 4 6\n",
            "Vel at 3,1,1 is 5 6\n",
            "Vel at 3,1,2 is 6 6\n",
            "Vel at 3,2,0 is 5 12\n",
            "Vel at 3,2,1 is 6 12\n",
            "Vel at 3,2,2 is 7 12\n",
            "Vel at 3,3,0 is 6 18\n",
            "Vel at 3,3,1 is 7 18\n",
            "Vel at 3,3,2 is 8 18\n",
            "Vel at 4,0,0 is 4 0\n",
            "Vel at 4,0,1 is 5 0\n",
            "Vel at 4,0,2 is 6 0\n",
            "Vel at 4,1,0 is 5 8\n",
            "Vel at 4,1,1 is 6 8\n",
            "Vel at 4,1,2 is 7 8\n",
            "Vel at 4,2,0 is 6 16\n",
            "Vel at 4,2,1 is 7 16\n",
            "Vel at 4,2,2 is 8 16\n",
            "Vel at 4,3,0 is 7 24\n",
            "Vel at 4,3,1 is 8 24\n",
            "Vel at 4,3,2 is 9 24\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    }
  ]
}