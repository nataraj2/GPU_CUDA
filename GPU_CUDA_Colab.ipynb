{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXsGtOvpBlyX",
        "outputId": "00797d37-8aad-4ee0-cfd7-5656e49dae22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-e6cadkn0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-e6cadkn0\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=7563e7e036e4fd9f315eaf0255e70b104123a33fbe3527cdc5d494ddce4ac9d8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-swzsrego/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name my_curand.cu \n",
        "\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda_runtime_api.h>\n",
        "\n",
        "#include <iostream>\n",
        "#include <cmath>\n",
        "#include <vector>\n",
        "\n",
        "#include </content/src/ParallelForGPU.h>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "HOST DEVICE\n",
        "inline void test_function(int i, int j, int k, \n",
        "                          Array4<double> const &vel,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\tArray4<double> const &pressure) {\n",
        "\tvel(i, j, k) = i+j+k;\n",
        "\tpressure(i,j,k) = 2*i*j;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "\t\n",
        "\tint nx = 5, ny = 4, nz = 3;\n",
        "  \n",
        "\tMultiFab velfab(nx, ny, nz);\n",
        "\tMultiFab pressurefab(nx, ny, nz);\n",
        "\n",
        "\tauto vel = velfab.array();\n",
        "\tauto pressure = pressurefab.array();\n",
        "  \n",
        "\tParallelFor(nx, ny, nz,\n",
        "\t[=] DEVICE (int i, int j, int k) noexcept\n",
        "\t{\n",
        "\t\ttest_function(i, j, k, vel, pressure);\n",
        "\t});\n",
        "\n",
        "cudaDeviceProp prop;\n",
        "cudaGetDeviceProperties(&prop, 0);\n",
        "printf(\"Device name: %s\\n\", prop.name);\n",
        "printf(\"Total global memory: %lu bytes\\n\", prop.totalGlobalMem);\n",
        "printf(\"Shared memory per block: %lu bytes\\n\", prop.sharedMemPerBlock);\n",
        "printf(\"Maximum threads per block: %d\\n\", prop.maxThreadsPerBlock);\n",
        "printf(\"Clock rate: %d kHz\\n\", prop.clockRate);\n",
        "\n",
        "int device;\n",
        "    cudaGetDevice(&device);\n",
        "\n",
        "    int mp_count;\n",
        "    cudaDeviceGetAttribute(&mp_count, cudaDevAttrMultiProcessorCount, device);\n",
        "\n",
        "    int max_threads_per_mp;\n",
        "    cudaDeviceGetAttribute(&max_threads_per_mp, cudaDevAttrMaxThreadsPerMultiProcessor, device);\n",
        "\n",
        "    int total_threads = mp_count * max_threads_per_mp;\n",
        "    printf(\"Total number of threads on device %d: %d %d %d\\n\", device, mp_count, max_threads_per_mp, total_threads);\n",
        "\n",
        "\n",
        "\n",
        "\tcudaDeviceSynchronize();\n",
        "\n",
        "\tfor(int i=0;i<nx;i++){\n",
        "\t\tfor(int j=0;j<ny;j++){\n",
        "\t\t\tfor(int k=0;k<nz;k++){\n",
        "\t\t\t\tcout << \"Vel at \" << i << \",\" << j << \",\" << k << \" is \" << vel(i,j,k) << \" \" << pressure(i,j,k) << \"\\n\";\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\n",
        "return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zi1hPjyNKyGr",
        "outputId": "d497f7ae-169b-4620-d017-94fc547bbcf5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/my_curand.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name ParallelForGPU.h\n",
        "\n",
        "#define HOST __host__\n",
        "#define DEVICE __device__\n",
        "\n",
        "#define GPU_MAX_THREADS 512\n",
        "\n",
        "#define LAUNCH_KERNEL(MT, blocks, threads, sharedMem, ... ) \\\n",
        "        launch_global<MT><<<blocks, threads, sharedMem>>>(__VA_ARGS__)\n",
        "\n",
        "template<typename T>\n",
        "struct Array4{\n",
        "\tT* data;\n",
        "\tint jstride;\n",
        "\tint kstride;\n",
        "\n",
        "  constexpr Array4(T* a_p): data(a_p){};\n",
        "\n",
        "\tpublic:\n",
        "    \t__host__ __device__\n",
        "\t\tT& operator()(int i, int j, int k)const noexcept{\n",
        "\t\t\t\t\t\treturn data[i + j*jstride + k*kstride];\n",
        "\t\t}\n",
        "};\n",
        "\n",
        "template<int launch_bounds_max_threads, class L>\n",
        "__launch_bounds__(launch_bounds_max_threads)\n",
        "__global__ void launch_global (L f0) { f0(); }\n",
        "\n",
        "template <typename F>\n",
        "DEVICE\n",
        "auto call_f(F const &f, int i, int j, int k){\n",
        "\tf(i, j, k);\n",
        "}\n",
        "\n",
        "template<class L>\n",
        "void ParallelFor(int nx, int ny, int nz, L &&f){\n",
        "\t\tint len_xy = nx*ny;\n",
        "\t\tint len_x = nx;\n",
        "\t\tint ncells = nx*ny*nz;\n",
        "\t\tint numBlocks = (std::max(ncells,1) + GPU_MAX_THREADS - 1 )/GPU_MAX_THREADS;\n",
        "\t\tint numThreads = GPU_MAX_THREADS;\n",
        "\t\tstd::cout << \"Launching \" << numBlocks << \" blocks \" << \"\\n\";\n",
        "\t\tLAUNCH_KERNEL(GPU_MAX_THREADS, numBlocks, numThreads, 0,\n",
        "    \t\t[=] DEVICE () noexcept{\t\n",
        "\t\t\tfor(int icell = blockDim.x*blockIdx.x+threadIdx.x, stride = blockDim.x*gridDim.x;\n",
        "        \ticell < nx*ny*nz; icell += stride){\n",
        "\t\t\t\tint k = icell/len_xy;\n",
        "\t\t\t\tint j = (icell - k*len_xy)/len_x;\n",
        "\t\t\t\tint i = (icell - k*len_xy - j*len_x); \n",
        "\t\t\t\tcall_f(f, i, j, k);\t\n",
        "\t\t\t}\n",
        "\t\t});\n",
        "}\n",
        "\n",
        "class MultiFab{\n",
        "\t\t\n",
        "\t\tint nx, ny, nz;\n",
        "\n",
        "\t\tpublic:\n",
        "\t\t\n",
        "\t\tMultiFab(int a_nx, int a_ny, int a_nz): nx(a_nx), ny(a_ny), nz(a_nz){};\n",
        "\n",
        "\t\tArray4<double> array()\n",
        "\t\t{\n",
        "\t\t\t\tArray4<double> *vec;\n",
        "  \t\t\tcudaMallocManaged((void**)&vec, sizeof(Array4<double>));\n",
        "  \t\t\tcudaMallocManaged((void**)&(vec[0].data), nx*ny*nz*sizeof(double));\n",
        "\t\t\t\tvec[0].jstride = nx;\n",
        "\t\t\t\tvec[0].kstride = nx*ny;\n",
        "\t\t\t\treturn vec[0];\n",
        "\t\t}\t\t\n",
        "};"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vsf5hDw3EHTD",
        "outputId": "9c8c4c60-83ca-4fa9-f2a6-9fa460311f0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/ParallelForGPU.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name ParallelForCPU.h\n",
        "\n",
        "#define HOST \n",
        "#define DEVICE \n",
        "\n",
        "template<typename T>\n",
        "struct Array4{\n",
        "\tT* data;\n",
        "\tint jstride;\n",
        "\tint kstride;\n",
        "\n",
        "  constexpr Array4(T* a_p): data(a_p){};\n",
        "\n",
        "\tpublic:\n",
        "    \t__host__ __device__\n",
        "\t\tT& operator()(int i, int j, int k)const noexcept{\n",
        "\t\t\t\t\t\treturn data[i + j*jstride + k*kstride];\n",
        "\t\t}\n",
        "};\n",
        "\n",
        "template <typename F>\n",
        "auto call_f(F const &f, int i, int j, int k){\n",
        "\tf(i, j, k);\n",
        "}\n",
        "\n",
        "template<class L>\n",
        "void ParallelFor(int nx, int ny, int nz, L &&f){\n",
        "\tfor(int i=0;i<nx;i++){\n",
        "\t  for(int j=0;j<ny;j++){\n",
        "\t\t\t\tfor(int k=0;k<nz;k++){\n",
        "\t\t\t\tcall_f(f, i, j, k);\t\n",
        "\t\t\t}\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "class MultiFab{\n",
        "\t\t\n",
        "\t\tint nx, ny, nz;\n",
        "\n",
        "\t\tpublic:\n",
        "\t\t\n",
        "\t\tMultiFab(int a_nx, int a_ny, int a_nz): nx(a_nx), ny(a_ny), nz(a_nz){};\n",
        "\n",
        "\t\tArray4<double> array()\n",
        "\t\t{\n",
        "\t\t\t\tArray4<double> *vec;\n",
        "        vec = (Array4<double>*)malloc(sizeof(Array4<double>));\n",
        "        vec[0].data = (double*)malloc(nx*ny*nz*sizeof(double));\n",
        "\t\t\t\tvec[0].jstride = nx;\n",
        "\t\t\t\tvec[0].kstride = nx*ny;\n",
        "\t\t\t\treturn vec[0];\n",
        "\t\t}\t\t\n",
        "};"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rtLOSJLmJPxG",
        "outputId": "683e0d16-68cd-44b0-82af-8d925cf87e9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/ParallelForCPU.h'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -expt-extended-lambda --expt-relaxed-constexpr --forward-unknown-to-host-compiler --Werror ext-lambda-captures-this -Xcudafe --diag_suppress=esa_on_defaulted_function_ignored -o /content/src/my_curand /content/src/my_curand.cu -lcurand\n"
      ],
      "metadata": {
        "id": "0VMQbIGlLCps"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!compute-sanitizer /content/src/my_curand\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiCSoucHLFoz",
        "outputId": "3c4e406d-7e2a-4c83-af3d-83455b7ed5f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= COMPUTE-SANITIZER\n",
            "Launching 1 blocks \n",
            "Device name: Tesla T4\n",
            "Total global memory: 15835398144 bytes\n",
            "Shared memory per block: 49152 bytes\n",
            "Maximum threads per block: 1024\n",
            "Clock rate: 1590000 kHz\n",
            "Total number of threads on device 0: 40 1024 40960\n",
            "Vel at 0,0,0 is 0 0\n",
            "Vel at 0,0,1 is 1 0\n",
            "Vel at 0,0,2 is 2 0\n",
            "Vel at 0,1,0 is 1 0\n",
            "Vel at 0,1,1 is 2 0\n",
            "Vel at 0,1,2 is 3 0\n",
            "Vel at 0,2,0 is 2 0\n",
            "Vel at 0,2,1 is 3 0\n",
            "Vel at 0,2,2 is 4 0\n",
            "Vel at 0,3,0 is 3 0\n",
            "Vel at 0,3,1 is 4 0\n",
            "Vel at 0,3,2 is 5 0\n",
            "Vel at 1,0,0 is 1 0\n",
            "Vel at 1,0,1 is 2 0\n",
            "Vel at 1,0,2 is 3 0\n",
            "Vel at 1,1,0 is 2 2\n",
            "Vel at 1,1,1 is 3 2\n",
            "Vel at 1,1,2 is 4 2\n",
            "Vel at 1,2,0 is 3 4\n",
            "Vel at 1,2,1 is 4 4\n",
            "Vel at 1,2,2 is 5 4\n",
            "Vel at 1,3,0 is 4 6\n",
            "Vel at 1,3,1 is 5 6\n",
            "Vel at 1,3,2 is 6 6\n",
            "Vel at 2,0,0 is 2 0\n",
            "Vel at 2,0,1 is 3 0\n",
            "Vel at 2,0,2 is 4 0\n",
            "Vel at 2,1,0 is 3 4\n",
            "Vel at 2,1,1 is 4 4\n",
            "Vel at 2,1,2 is 5 4\n",
            "Vel at 2,2,0 is 4 8\n",
            "Vel at 2,2,1 is 5 8\n",
            "Vel at 2,2,2 is 6 8\n",
            "Vel at 2,3,0 is 5 12\n",
            "Vel at 2,3,1 is 6 12\n",
            "Vel at 2,3,2 is 7 12\n",
            "Vel at 3,0,0 is 3 0\n",
            "Vel at 3,0,1 is 4 0\n",
            "Vel at 3,0,2 is 5 0\n",
            "Vel at 3,1,0 is 4 6\n",
            "Vel at 3,1,1 is 5 6\n",
            "Vel at 3,1,2 is 6 6\n",
            "Vel at 3,2,0 is 5 12\n",
            "Vel at 3,2,1 is 6 12\n",
            "Vel at 3,2,2 is 7 12\n",
            "Vel at 3,3,0 is 6 18\n",
            "Vel at 3,3,1 is 7 18\n",
            "Vel at 3,3,2 is 8 18\n",
            "Vel at 4,0,0 is 4 0\n",
            "Vel at 4,0,1 is 5 0\n",
            "Vel at 4,0,2 is 6 0\n",
            "Vel at 4,1,0 is 5 8\n",
            "Vel at 4,1,1 is 6 8\n",
            "Vel at 4,1,2 is 7 8\n",
            "Vel at 4,2,0 is 6 16\n",
            "Vel at 4,2,1 is 7 16\n",
            "Vel at 4,2,2 is 8 16\n",
            "Vel at 4,3,0 is 7 24\n",
            "Vel at 4,3,1 is 8 24\n",
            "Vel at 4,3,2 is 9 24\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    }
  ]
}